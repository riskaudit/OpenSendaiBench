{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import rioxarray as rxr\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image \n",
    "from constants import labels\n",
    "\n",
    "from constants import labels\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import copy\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torch.nn.functional import relu\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenSendaiBenchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    An implementation of a PyTorch dataset for loading pairs of observable variables and ground truth labels.\n",
    "    Inspired by https://pytorch.org/tutorials/beginner/data_loading_tutorial.html.\n",
    "    \"\"\"\n",
    "    def __init__(self, obsvariables_path: str, groundtruth_path: str, country: str, signals: list, transform: transforms = None):\n",
    "        \"\"\"\n",
    "        Constructs an OpenSendaiBenchDataset.\n",
    "        :param obsvariables_path: Path to the source folder of observable variables\n",
    "        :param groundtruth_path: Path to the source folder of corresponding ground truth labels\n",
    "        :param transform: Callable transformation to apply to images upon loading\n",
    "        \"\"\"\n",
    "        self.obsvariables_path = obsvariables_path\n",
    "        self.groundtruth_path = groundtruth_path\n",
    "        self.country = country\n",
    "        self.signals = signals\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Implements the len(SeaIceDataset) magic method. Required to implement by Dataset superclass.\n",
    "        When training/testing, this method tells our training loop how much longer we have to go in our Dataset.\n",
    "        :return: Length of OpenSendaiBenchDataset\n",
    "        \"\"\"\n",
    "        return 100 #len(self.groundtruth_files)/labels[self.country]\n",
    "\n",
    "    def __getitem__(self, i: int):\n",
    "        \"\"\"\n",
    "        Implements the OpenSendaiBenchDataset[i] magic method. Required to implement by Dataset superclass.\n",
    "        When training/testing, this method is used to actually fetch data.\n",
    "        :param i: Index of which image pair to fetch\n",
    "        :return: Dictionary with pairs of observable variables and ground truth labels.\n",
    "        \"\"\"\n",
    "\n",
    "        obsvariable = np.zeros([len(self.signals),372,372])\n",
    "        obsvariable_8x8 = np.zeros([len(self.signals),8,8])\n",
    "        for s in range(len(self.signals)):\n",
    "            for file in glob.glob(str(os.getcwd()+self.obsvariables_path+\n",
    "                                    '**/'+self.country+'_*/'+self.country+'_'+\n",
    "                                    str(i)+'_'+'of_*/2019*_'+self.signals[s]+'.tif')):\n",
    "                a = cv2.imread(file, cv2.IMREAD_UNCHANGED)\n",
    "                a = a.reshape(1,a.shape[0],a.shape[1])\n",
    "                obsvariable[s,:,:] = a[0,0:372,0:372]\n",
    "            obsvariable_8x8[s,:,:] = cv2.resize(obsvariable[s,:,:], (8,8), interpolation = cv2.INTER_AREA)\n",
    "        groundtruth = np.zeros([len(labels[self.country]),8,8])\n",
    "        for w in range(len(labels[self.country])): # to make composite. in AFG, we got 5 bldgtypes\n",
    "            for file in glob.glob(str(os.getcwd()+self.groundtruth_path+\n",
    "                                      self.country+'*/tiles/images/'+\n",
    "                                      self.country+'_nbldg_'+labels[self.country][w]+'_'+str(i)+'_'+'of_'+'*.tif')):\n",
    "                a = cv2.imread(file, cv2.IMREAD_UNCHANGED)\n",
    "                # a = cv2.resize(a, (372,372), interpolation = cv2.INTER_NEAREST)\n",
    "                a = a.reshape(1,a.shape[0],a.shape[1])\n",
    "                groundtruth[w,:,:] = a\n",
    "\n",
    "        obsvariable = torch.from_numpy(obsvariable).float()\n",
    "        obsvariable_8x8 = torch.from_numpy(obsvariable_8x8).float()\n",
    "        groundtruth = torch.from_numpy(groundtruth).float()\n",
    "    \n",
    "        sample = {\"obsvariable\": obsvariable_8x8, \"groundtruth\": groundtruth}\n",
    "        if self.transform:\n",
    "            sample = {\"obsvariable\": self.transform(obsvariable_8x8),\n",
    "                      \"groundtruth\": self.transform(groundtruth).squeeze(0).long()}\n",
    "        return sample\n",
    "\n",
    "    def visualise(self, i):\n",
    "        \"\"\"\n",
    "        Allows us to visualise a particular SAR/chart pair.\n",
    "        :param i: Index of which image pair to visualise\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        sample = self[i]\n",
    "        fig1, axs1 = plt.subplots(1,len(self.signals))\n",
    "        for s in range(len(self.signals)):\n",
    "            axs1[s].imshow(sample['obsvariable'][s,:,:])\n",
    "            axs1[s].set_title(str(self.signals[s]))\n",
    "            axs1[s].set_xticks([])\n",
    "            axs1[s].set_yticks([])\n",
    "        plt.tight_layout()\n",
    " \n",
    "        fig2, axs2 = plt.subplots(1,len(labels[self.country]))\n",
    "        for w in range(len(labels[self.country])): \n",
    "            axs2[w].imshow(sample['groundtruth'][w,:,:])\n",
    "            axs2[w].set_title(labels[self.country][w])\n",
    "            axs2[w].set_xticks([])\n",
    "            axs2[w].set_yticks([])\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'obsvariable': tensor([[[1.5122e-02, 1.5987e-02, 1.1268e-02, 9.3391e-03, 1.3948e-02,\n",
       "           1.3149e-02, 8.1364e-03, 1.1452e-02],\n",
       "          [1.7093e-02, 1.4680e-02, 1.2230e-02, 8.7238e-03, 9.4277e-03,\n",
       "           4.7684e-03, 7.2373e-03, 1.1510e-02],\n",
       "          [1.5275e-02, 1.8039e-02, 1.6348e-02, 5.4896e-03, 1.4436e-02,\n",
       "           2.8196e-02, 3.3467e-02, 3.2700e-02],\n",
       "          [1.8475e-02, 2.0318e-02, 1.6334e-02, 2.3637e-02, 1.6341e-02,\n",
       "           1.4217e-02, 1.2799e-02, 1.5496e-02],\n",
       "          [1.7397e-02, 2.1403e-02, 2.0265e-02, 1.7771e-02, 1.5368e-02,\n",
       "           1.4973e-02, 1.2583e-02, 1.1949e-02],\n",
       "          [1.7684e-02, 2.0368e-02, 2.0896e-02, 1.6181e-02, 1.8122e-02,\n",
       "           1.5642e-02, 1.5208e-02, 1.3743e-02],\n",
       "          [1.8250e-02, 1.3803e-02, 1.6003e-02, 1.7603e-02, 1.7324e-02,\n",
       "           1.5701e-02, 1.3437e-02, 1.5846e-02],\n",
       "          [1.4465e-02, 1.9324e-02, 1.4849e-02, 1.2502e-02, 1.1770e-02,\n",
       "           1.1641e-02, 1.8955e-02, 1.8240e-02]],\n",
       " \n",
       "         [[1.1525e-01, 1.1040e-01, 9.6484e-02, 6.7963e-02, 8.1189e-02,\n",
       "           8.0253e-02, 7.3917e-02, 7.3140e-02],\n",
       "          [1.3869e-01, 1.3266e-01, 1.1179e-01, 7.0058e-02, 6.1048e-02,\n",
       "           2.9232e-02, 5.0368e-02, 6.6757e-02],\n",
       "          [1.0695e-01, 1.1080e-01, 1.2537e-01, 4.1042e-02, 8.1245e-02,\n",
       "           1.3409e-01, 1.7542e-01, 1.8169e-01],\n",
       "          [1.1185e-01, 1.1772e-01, 1.0312e-01, 1.4538e-01, 1.0663e-01,\n",
       "           1.1249e-01, 7.9052e-02, 1.0791e-01],\n",
       "          [1.0697e-01, 1.1938e-01, 1.0380e-01, 1.1261e-01, 1.1108e-01,\n",
       "           1.0351e-01, 8.3415e-02, 8.2071e-02],\n",
       "          [1.1720e-01, 1.4538e-01, 1.1431e-01, 1.1266e-01, 1.3156e-01,\n",
       "           1.0307e-01, 9.4703e-02, 9.2477e-02],\n",
       "          [1.0338e-01, 1.0470e-01, 1.1136e-01, 1.3618e-01, 1.0664e-01,\n",
       "           9.9892e-02, 1.0600e-01, 1.0436e-01],\n",
       "          [1.3080e-01, 1.2907e-01, 9.4540e-02, 9.3826e-02, 9.5452e-02,\n",
       "           1.1540e-01, 1.3226e-01, 9.7847e-02]],\n",
       " \n",
       "         [[2.2332e+03, 2.0987e+03, 2.2519e+03, 2.3378e+03, 2.2853e+03,\n",
       "           2.3025e+03, 2.3767e+03, 2.3189e+03],\n",
       "          [2.1408e+03, 2.1480e+03, 2.3309e+03, 2.5412e+03, 2.2499e+03,\n",
       "           2.2290e+03, 2.2426e+03, 2.2985e+03],\n",
       "          [2.1770e+03, 2.1100e+03, 2.2338e+03, 2.4924e+03, 2.2597e+03,\n",
       "           2.2296e+03, 2.2807e+03, 2.3085e+03],\n",
       "          [2.1119e+03, 2.0486e+03, 2.2626e+03, 2.3371e+03, 2.2272e+03,\n",
       "           2.3268e+03, 2.3298e+03, 2.2218e+03],\n",
       "          [2.0390e+03, 1.9943e+03, 2.0978e+03, 2.2148e+03, 2.3046e+03,\n",
       "           2.3114e+03, 2.3841e+03, 2.3353e+03],\n",
       "          [2.0589e+03, 1.9580e+03, 1.9948e+03, 2.1537e+03, 2.1460e+03,\n",
       "           2.1906e+03, 2.2878e+03, 2.4980e+03],\n",
       "          [1.9321e+03, 2.1497e+03, 2.0699e+03, 2.0754e+03, 2.1518e+03,\n",
       "           2.2081e+03, 2.5030e+03, 2.2597e+03],\n",
       "          [2.0483e+03, 1.9650e+03, 2.2477e+03, 2.3608e+03, 2.4605e+03,\n",
       "           2.3736e+03, 2.0574e+03, 1.9443e+03]],\n",
       " \n",
       "         [[2.4180e+03, 2.2560e+03, 2.4486e+03, 2.5678e+03, 2.5089e+03,\n",
       "           2.5412e+03, 2.6683e+03, 2.5689e+03],\n",
       "          [2.3457e+03, 2.3587e+03, 2.5436e+03, 2.7777e+03, 2.4774e+03,\n",
       "           2.4466e+03, 2.4547e+03, 2.5337e+03],\n",
       "          [2.3880e+03, 2.2929e+03, 2.4134e+03, 2.7100e+03, 2.4445e+03,\n",
       "           2.3895e+03, 2.4816e+03, 2.5227e+03],\n",
       "          [2.2868e+03, 2.2123e+03, 2.4757e+03, 2.5318e+03, 2.4016e+03,\n",
       "           2.5082e+03, 2.5425e+03, 2.4024e+03],\n",
       "          [2.2310e+03, 2.1427e+03, 2.2655e+03, 2.4208e+03, 2.5174e+03,\n",
       "           2.4860e+03, 2.6395e+03, 2.5723e+03],\n",
       "          [2.2446e+03, 2.1100e+03, 2.1632e+03, 2.3510e+03, 2.3363e+03,\n",
       "           2.3436e+03, 2.4278e+03, 2.6721e+03],\n",
       "          [2.0933e+03, 2.3487e+03, 2.2288e+03, 2.2461e+03, 2.3200e+03,\n",
       "           2.3871e+03, 2.7373e+03, 2.4302e+03],\n",
       "          [2.2403e+03, 2.0981e+03, 2.4088e+03, 2.5470e+03, 2.6706e+03,\n",
       "           2.5879e+03, 2.1839e+03, 2.0475e+03]],\n",
       " \n",
       "         [[2.8735e+03, 2.6891e+03, 2.9169e+03, 3.0306e+03, 2.9525e+03,\n",
       "           2.9902e+03, 3.1608e+03, 3.0323e+03],\n",
       "          [2.7647e+03, 2.7755e+03, 2.9899e+03, 3.2501e+03, 2.9476e+03,\n",
       "           2.9443e+03, 2.9733e+03, 3.0456e+03],\n",
       "          [2.8245e+03, 2.7029e+03, 2.8357e+03, 3.2346e+03, 2.9313e+03,\n",
       "           2.8313e+03, 2.8918e+03, 2.9557e+03],\n",
       "          [2.6946e+03, 2.5829e+03, 2.8840e+03, 2.9591e+03, 2.8325e+03,\n",
       "           2.9632e+03, 3.0147e+03, 2.8462e+03],\n",
       "          [2.6078e+03, 2.4738e+03, 2.6185e+03, 2.8168e+03, 2.9498e+03,\n",
       "           2.9219e+03, 3.0942e+03, 3.0237e+03],\n",
       "          [2.6363e+03, 2.4501e+03, 2.5240e+03, 2.7487e+03, 2.7153e+03,\n",
       "           2.7294e+03, 2.8224e+03, 3.1071e+03],\n",
       "          [2.4526e+03, 2.7528e+03, 2.6056e+03, 2.6139e+03, 2.6813e+03,\n",
       "           2.7643e+03, 3.1418e+03, 2.7908e+03],\n",
       "          [2.6225e+03, 2.4306e+03, 2.7810e+03, 2.9440e+03, 3.0760e+03,\n",
       "           2.9838e+03, 2.5069e+03, 2.3389e+03]],\n",
       " \n",
       "         [[3.2555e+03, 3.0322e+03, 3.2982e+03, 3.4411e+03, 3.3065e+03,\n",
       "           3.3603e+03, 3.6177e+03, 3.4214e+03],\n",
       "          [3.0567e+03, 3.0571e+03, 3.3378e+03, 3.6799e+03, 3.3737e+03,\n",
       "           3.4388e+03, 3.5016e+03, 3.5674e+03],\n",
       "          [3.1648e+03, 2.9972e+03, 3.1397e+03, 3.7370e+03, 3.4253e+03,\n",
       "           3.2600e+03, 3.2984e+03, 3.3801e+03],\n",
       "          [2.9859e+03, 2.8310e+03, 3.2107e+03, 3.3324e+03, 3.1757e+03,\n",
       "           3.3277e+03, 3.4061e+03, 3.1915e+03],\n",
       "          [2.8568e+03, 2.6804e+03, 2.8827e+03, 3.1166e+03, 3.2775e+03,\n",
       "           3.2713e+03, 3.4970e+03, 3.4031e+03],\n",
       "          [2.9133e+03, 2.6539e+03, 2.7663e+03, 3.0465e+03, 2.9548e+03,\n",
       "           3.0076e+03, 3.1076e+03, 3.4608e+03],\n",
       "          [2.6805e+03, 3.0670e+03, 2.8752e+03, 2.8617e+03, 2.9297e+03,\n",
       "           3.0430e+03, 3.4695e+03, 3.0336e+03],\n",
       "          [2.8906e+03, 2.6043e+03, 3.0485e+03, 3.2525e+03, 3.4140e+03,\n",
       "           3.3087e+03, 2.6816e+03, 2.4349e+03]],\n",
       " \n",
       "         [[3.5501e+03, 3.3531e+03, 3.6051e+03, 3.7503e+03, 3.6442e+03,\n",
       "           3.6881e+03, 3.9247e+03, 3.7514e+03],\n",
       "          [3.4018e+03, 3.3970e+03, 3.6523e+03, 3.9844e+03, 3.6635e+03,\n",
       "           3.6555e+03, 3.7190e+03, 3.7933e+03],\n",
       "          [3.4810e+03, 3.3292e+03, 3.4751e+03, 3.9916e+03, 3.6426e+03,\n",
       "           3.4980e+03, 3.5182e+03, 3.6249e+03],\n",
       "          [3.3266e+03, 3.1846e+03, 3.5248e+03, 3.5962e+03, 3.5031e+03,\n",
       "           3.6520e+03, 3.7285e+03, 3.5209e+03],\n",
       "          [3.2170e+03, 3.0378e+03, 3.2139e+03, 3.4418e+03, 3.6083e+03,\n",
       "           3.6013e+03, 3.7998e+03, 3.7221e+03],\n",
       "          [3.2595e+03, 3.0232e+03, 3.1250e+03, 3.3866e+03, 3.3203e+03,\n",
       "           3.3731e+03, 3.4555e+03, 3.7544e+03],\n",
       "          [3.0605e+03, 3.4110e+03, 3.2120e+03, 3.2193e+03, 3.2904e+03,\n",
       "           3.3784e+03, 3.7240e+03, 3.3612e+03],\n",
       "          [3.2555e+03, 2.9827e+03, 3.3868e+03, 3.5459e+03, 3.6782e+03,\n",
       "           3.5845e+03, 3.0322e+03, 2.8443e+03]],\n",
       " \n",
       "         [[3.7823e+03, 3.6570e+03, 3.8241e+03, 3.9718e+03, 3.9667e+03,\n",
       "           3.9688e+03, 4.1118e+03, 4.0552e+03],\n",
       "          [3.8099e+03, 3.8168e+03, 3.9157e+03, 4.1433e+03, 3.8577e+03,\n",
       "           3.6911e+03, 3.7450e+03, 3.8323e+03],\n",
       "          [3.7883e+03, 3.6997e+03, 3.8393e+03, 4.0701e+03, 3.6796e+03,\n",
       "           3.6097e+03, 3.5739e+03, 3.7239e+03],\n",
       "          [3.7476e+03, 3.6657e+03, 3.8361e+03, 3.7566e+03, 3.8336e+03,\n",
       "           3.9528e+03, 4.0014e+03, 3.8580e+03],\n",
       "          [3.7254e+03, 3.5528e+03, 3.6189e+03, 3.7873e+03, 3.9229e+03,\n",
       "           3.9036e+03, 4.0170e+03, 3.9887e+03],\n",
       "          [3.6651e+03, 3.5305e+03, 3.6060e+03, 3.7818e+03, 3.8159e+03,\n",
       "           3.8226e+03, 3.8634e+03, 3.9833e+03],\n",
       "          [3.5986e+03, 3.7897e+03, 3.6188e+03, 3.6925e+03, 3.7564e+03,\n",
       "           3.7617e+03, 3.8666e+03, 3.7469e+03],\n",
       "          [3.7410e+03, 3.5644e+03, 3.8088e+03, 3.8046e+03, 3.8401e+03,\n",
       "           3.7680e+03, 3.5585e+03, 3.5936e+03]],\n",
       " \n",
       "         [[3.9104e+03, 3.8132e+03, 3.9619e+03, 4.1122e+03, 4.1305e+03,\n",
       "           4.1195e+03, 4.2425e+03, 4.2178e+03],\n",
       "          [3.9827e+03, 3.9885e+03, 4.0585e+03, 4.2637e+03, 3.9802e+03,\n",
       "           3.7633e+03, 3.8192e+03, 3.9109e+03],\n",
       "          [3.9406e+03, 3.8710e+03, 4.0076e+03, 4.1656e+03, 3.7566e+03,\n",
       "           3.7066e+03, 3.6576e+03, 3.8215e+03],\n",
       "          [3.9350e+03, 3.8768e+03, 3.9998e+03, 3.8647e+03, 3.9938e+03,\n",
       "           4.1053e+03, 4.1508e+03, 4.0235e+03],\n",
       "          [3.9294e+03, 3.7687e+03, 3.8056e+03, 3.9496e+03, 4.0730e+03,\n",
       "           4.0582e+03, 4.1565e+03, 4.1457e+03],\n",
       "          [3.8519e+03, 3.7338e+03, 3.8125e+03, 3.9650e+03, 4.0151e+03,\n",
       "           4.0205e+03, 4.0512e+03, 4.1236e+03],\n",
       "          [3.8215e+03, 3.9701e+03, 3.8035e+03, 3.8962e+03, 3.9591e+03,\n",
       "           3.9441e+03, 3.9684e+03, 3.9232e+03],\n",
       "          [3.9498e+03, 3.7911e+03, 4.0027e+03, 3.9422e+03, 3.9502e+03,\n",
       "           3.8885e+03, 3.7825e+03, 3.8550e+03]],\n",
       " \n",
       "         [[3.9719e+03, 3.8804e+03, 4.0341e+03, 4.2036e+03, 4.2304e+03,\n",
       "           4.2223e+03, 4.3515e+03, 4.3284e+03],\n",
       "          [4.0893e+03, 4.0957e+03, 4.1478e+03, 4.3562e+03, 4.0616e+03,\n",
       "           3.8103e+03, 3.8551e+03, 3.9644e+03],\n",
       "          [4.0431e+03, 3.9726e+03, 4.1019e+03, 4.2289e+03, 3.8048e+03,\n",
       "           3.7667e+03, 3.7385e+03, 3.9173e+03],\n",
       "          [4.0278e+03, 3.9912e+03, 4.1102e+03, 3.9423e+03, 4.0813e+03,\n",
       "           4.1777e+03, 4.2370e+03, 4.1059e+03],\n",
       "          [4.0281e+03, 3.8692e+03, 3.8936e+03, 4.0348e+03, 4.1485e+03,\n",
       "           4.1184e+03, 4.2355e+03, 4.2227e+03],\n",
       "          [3.9364e+03, 3.8294e+03, 3.9056e+03, 4.0520e+03, 4.1168e+03,\n",
       "           4.1029e+03, 4.1168e+03, 4.1677e+03],\n",
       "          [3.9228e+03, 4.0553e+03, 3.8785e+03, 3.9916e+03, 4.0545e+03,\n",
       "           4.0345e+03, 4.0342e+03, 4.0060e+03],\n",
       "          [4.0500e+03, 3.8934e+03, 4.0852e+03, 4.0056e+03, 4.0099e+03,\n",
       "           3.9583e+03, 3.8679e+03, 3.9541e+03]],\n",
       " \n",
       "         [[3.9602e+03, 3.8851e+03, 4.0258e+03, 4.1815e+03, 4.2098e+03,\n",
       "           4.1883e+03, 4.2977e+03, 4.2904e+03],\n",
       "          [4.0522e+03, 4.0498e+03, 4.1175e+03, 4.3239e+03, 4.0190e+03,\n",
       "           3.7478e+03, 3.8031e+03, 3.9033e+03],\n",
       "          [4.0031e+03, 3.9444e+03, 4.0732e+03, 4.1821e+03, 3.7538e+03,\n",
       "           3.7344e+03, 3.7022e+03, 3.8705e+03],\n",
       "          [4.0121e+03, 3.9746e+03, 4.0760e+03, 3.9032e+03, 4.0514e+03,\n",
       "           4.1585e+03, 4.2074e+03, 4.0859e+03],\n",
       "          [4.0180e+03, 3.8740e+03, 3.8983e+03, 4.0098e+03, 4.1195e+03,\n",
       "           4.1197e+03, 4.2115e+03, 4.2067e+03],\n",
       "          [3.9382e+03, 3.8319e+03, 3.9121e+03, 4.0474e+03, 4.1018e+03,\n",
       "           4.1150e+03, 4.1346e+03, 4.1680e+03],\n",
       "          [3.9352e+03, 4.0545e+03, 3.8833e+03, 3.9879e+03, 4.0502e+03,\n",
       "           4.0267e+03, 3.9776e+03, 3.9804e+03],\n",
       "          [4.0532e+03, 3.9022e+03, 4.0819e+03, 3.9826e+03, 3.9763e+03,\n",
       "           3.9247e+03, 3.8594e+03, 3.9571e+03]],\n",
       " \n",
       "         [[4.5322e+03, 4.4520e+03, 4.6075e+03, 4.7214e+03, 4.7383e+03,\n",
       "           4.7252e+03, 4.8238e+03, 4.7865e+03],\n",
       "          [4.6124e+03, 4.5881e+03, 4.6546e+03, 4.8503e+03, 4.5020e+03,\n",
       "           4.2585e+03, 4.3356e+03, 4.4200e+03],\n",
       "          [4.5419e+03, 4.5009e+03, 4.6057e+03, 4.7042e+03, 4.2893e+03,\n",
       "           4.2843e+03, 4.2548e+03, 4.3976e+03],\n",
       "          [4.5579e+03, 4.5307e+03, 4.5989e+03, 4.4216e+03, 4.5757e+03,\n",
       "           4.7146e+03, 4.7292e+03, 4.5824e+03],\n",
       "          [4.5715e+03, 4.4651e+03, 4.4724e+03, 4.5455e+03, 4.6191e+03,\n",
       "           4.6538e+03, 4.6869e+03, 4.6649e+03],\n",
       "          [4.5271e+03, 4.4216e+03, 4.4653e+03, 4.5789e+03, 4.6292e+03,\n",
       "           4.6510e+03, 4.6789e+03, 4.7249e+03],\n",
       "          [4.5232e+03, 4.6396e+03, 4.4183e+03, 4.4851e+03, 4.6028e+03,\n",
       "           4.6114e+03, 4.5695e+03, 4.5794e+03],\n",
       "          [4.6170e+03, 4.4596e+03, 4.6329e+03, 4.5319e+03, 4.5737e+03,\n",
       "           4.5227e+03, 4.4383e+03, 4.5145e+03]],\n",
       " \n",
       "         [[3.7709e+03, 3.5342e+03, 3.8305e+03, 3.9651e+03, 3.8263e+03,\n",
       "           3.8669e+03, 4.1059e+03, 3.8830e+03],\n",
       "          [3.5556e+03, 3.5907e+03, 3.8533e+03, 4.1324e+03, 3.8826e+03,\n",
       "           3.9587e+03, 4.0355e+03, 4.0888e+03],\n",
       "          [3.6207e+03, 3.4558e+03, 3.5856e+03, 4.2702e+03, 4.0239e+03,\n",
       "           3.9076e+03, 3.9194e+03, 3.9822e+03],\n",
       "          [3.4921e+03, 3.3287e+03, 3.7000e+03, 3.7870e+03, 3.6128e+03,\n",
       "           3.7636e+03, 3.8903e+03, 3.6098e+03],\n",
       "          [3.4084e+03, 3.1735e+03, 3.3643e+03, 3.4846e+03, 3.5698e+03,\n",
       "           3.6634e+03, 3.9425e+03, 3.8234e+03],\n",
       "          [3.3681e+03, 3.1037e+03, 3.2265e+03, 3.5036e+03, 3.3479e+03,\n",
       "           3.4179e+03, 3.5332e+03, 3.7940e+03],\n",
       "          [3.1769e+03, 3.5184e+03, 3.2844e+03, 3.2869e+03, 3.3607e+03,\n",
       "           3.4627e+03, 3.7097e+03, 3.3907e+03],\n",
       "          [3.3990e+03, 3.0803e+03, 3.4455e+03, 3.5564e+03, 3.6854e+03,\n",
       "           3.5839e+03, 3.0639e+03, 2.9519e+03]],\n",
       " \n",
       "         [[3.4822e+03, 3.1465e+03, 3.5088e+03, 3.6161e+03, 3.4601e+03,\n",
       "           3.5074e+03, 3.7490e+03, 3.4737e+03],\n",
       "          [3.1123e+03, 3.1549e+03, 3.5038e+03, 3.7436e+03, 3.5682e+03,\n",
       "           3.8563e+03, 3.9461e+03, 3.9688e+03],\n",
       "          [3.2187e+03, 3.0273e+03, 3.1702e+03, 4.0551e+03, 3.9017e+03,\n",
       "           3.7166e+03, 3.7156e+03, 3.7336e+03],\n",
       "          [3.0643e+03, 2.8481e+03, 3.3034e+03, 3.4798e+03, 3.2180e+03,\n",
       "           3.4032e+03, 3.5303e+03, 3.2182e+03],\n",
       "          [2.9240e+03, 2.6983e+03, 2.9516e+03, 3.0850e+03, 3.1663e+03,\n",
       "           3.2730e+03, 3.6204e+03, 3.4702e+03],\n",
       "          [2.9158e+03, 2.6160e+03, 2.7584e+03, 3.0900e+03, 2.8605e+03,\n",
       "           2.9362e+03, 3.1267e+03, 3.4990e+03],\n",
       "          [2.6619e+03, 3.0972e+03, 2.8792e+03, 2.8090e+03, 2.9066e+03,\n",
       "           3.0596e+03, 3.4620e+03, 3.0253e+03],\n",
       "          [2.9181e+03, 2.5961e+03, 3.0229e+03, 3.2231e+03, 3.4190e+03,\n",
       "           3.2965e+03, 2.6171e+03, 2.4046e+03]]]),\n",
       " 'groundtruth': tensor([[[ 3.,  3.,  2.,  1.,  2.,  2.,  2.,  3.],\n",
       "          [ 3.,  3.,  1.,  3.,  3.,  2.,  3.,  2.],\n",
       "          [ 9.,  9.,  2.,  2.,  0.,  0.,  0.,  0.],\n",
       "          [ 8.,  8.,  2.,  2.,  0.,  0.,  0.,  1.],\n",
       "          [36., 36.,  3.,  3.,  2.,  2.,  2.,  2.],\n",
       "          [36., 35.,  3.,  3.,  3.,  3.,  2.,  1.],\n",
       "          [ 1.,  1.,  1.,  1.,  8.,  8., 17., 15.],\n",
       "          [ 1.,  1.,  2.,  1.,  9.,  9., 15., 15.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.],\n",
       "          [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "          [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "          [ 1.,  0.,  0.,  0.,  0.,  1.,  1.,  1.]],\n",
       " \n",
       "         [[ 1.,  1.,  0.,  1.,  1.,  0.,  0.,  1.],\n",
       "          [ 1.,  0.,  1.,  0.,  1.,  1.,  0.,  0.],\n",
       "          [ 3.,  2.,  1.,  0.,  0.,  1.,  0.,  0.],\n",
       "          [ 3.,  3.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [12., 11.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "          [12., 11.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "          [ 0.,  0.,  1.,  0.,  3.,  3.,  6.,  5.],\n",
       "          [ 0.,  0.,  0.,  0.,  2.,  2.,  6.,  5.]],\n",
       " \n",
       "         [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "          [ 0.,  1.,  0.,  1.,  1.,  0.,  0.,  0.],\n",
       "          [ 1.,  1.,  0.,  1.,  1.,  1.,  0.,  0.],\n",
       "          [ 2.,  3.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "          [ 2.,  2.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  1.,  0.,  1.,  1.,  1.,  0.,  1.],\n",
       "          [ 0.,  0.,  0.,  1.,  1.,  0.,  0.,  1.]]])}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = OpenSendaiBenchDataset( obsvariables_path=\"/obsvariables/\", \n",
    "                                        groundtruth_path=\"/groundtruth/\", \n",
    "                                        country='AFG', \n",
    "                                        signals = ['VH','VV','aerosol','blue','green','red','red1','red2','red3','nir','red4','vapor','swir1','swir2'])\n",
    "train_dataset[1]\n",
    "# dataset['groundtruth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  55.5683,   12.2554,   85.9665,   92.2534,   64.2853,   99.1348,\n",
       "            74.9290,  138.5744],\n",
       "         [  56.5746,   38.6449,   46.6596,    4.1989,   25.9319,   11.6244,\n",
       "            58.2409,  -34.6473],\n",
       "         [ 107.0879,   24.1759,  127.6262,   99.4314,  128.2288,   99.8934,\n",
       "           135.2706,  141.1273],\n",
       "         [  -6.1438,  -69.5443,   17.4839,  -60.8987,   -9.1270,  -47.2949,\n",
       "            41.9252,  -77.5270],\n",
       "         [  94.8010,   35.6969,   89.4153,   75.8144,   76.2929,   76.4074,\n",
       "            90.5115,  114.4455],\n",
       "         [ -10.5928,  -58.6679,    2.6615,  -47.7289,  -15.4975,  -27.9729,\n",
       "            26.6019,  -69.6666],\n",
       "         [ 106.8450,   83.3775,   93.8893,  105.8706,   70.8951,  147.3103,\n",
       "            78.0734,  161.0407],\n",
       "         [ -92.4618, -115.0424,  -90.7688,  -95.7780,  -77.5475,  -93.7511,\n",
       "           -40.9276,  -93.7736]],\n",
       "\n",
       "        [[  45.0114,  -63.1386,  101.0133,  -74.7596,   86.2678,  -85.8270,\n",
       "            75.5192,  -98.2799],\n",
       "         [-142.9656,   10.2106, -152.5605,   61.2510, -140.7249,   55.1470,\n",
       "          -116.0034,   27.3730],\n",
       "         [ -21.2898,  -46.1723,   13.4674,  -53.3673,   20.9986,  -84.4089,\n",
       "            35.3404,  -41.4272],\n",
       "         [-127.4783,   17.6042, -102.2100,   81.6041, -111.8210,   78.8124,\n",
       "          -107.3686,   96.5969],\n",
       "         [ -22.6128,  -78.9536,   49.8409,  -74.1487,   50.2009, -106.6010,\n",
       "            38.7610,  -38.3234],\n",
       "         [-144.4707,  -20.5447, -100.2263,   59.4371,  -94.7014,   74.9624,\n",
       "           -91.6465,   83.6830],\n",
       "         [  -7.3760,  -25.9288,   26.8161,  -28.2633,    1.7665,  -43.8781,\n",
       "            32.9021,   -4.4762],\n",
       "         [-116.0056,   85.9284,  -88.4281,  107.8007,  -71.2540,  122.6405,\n",
       "           -69.6085,  107.5840]],\n",
       "\n",
       "        [[-136.4021,  -43.0231,  -91.4888,  -47.1521,  -77.1284,   12.1598,\n",
       "           -45.6917,   31.4561],\n",
       "         [  97.0891,  122.6458,  108.4764,  104.2710,  122.6536,   73.7967,\n",
       "           116.5294,  -31.2576],\n",
       "         [ -85.8385, -110.5165,  -27.4478,  -90.3945,  -11.5473,  -26.6851,\n",
       "            13.2789,    9.5558],\n",
       "         [ 117.4574,   92.5387,  150.5227,   49.0603,  198.1862,   -1.1573,\n",
       "           176.9039,  -73.0099],\n",
       "         [-118.0146,  -90.6193,  -23.5262,  -49.0597,   23.5098,   12.3999,\n",
       "            46.6650,   17.1393],\n",
       "         [ 113.8801,   97.6052,  145.6508,   90.2792,  196.3760,   50.8658,\n",
       "           177.5641,  -30.1883],\n",
       "         [ -48.8731,  -81.3898,  -35.5142,  -50.9163,   -8.0334,   19.6174,\n",
       "            10.9476,  -11.5527],\n",
       "         [ 107.8722,   59.0536,  136.4560,   48.1959,  173.9708,   16.9225,\n",
       "           149.5620,    2.7669]],\n",
       "\n",
       "        [[  95.8124,  -69.9197,   55.4087,  -52.2156,   54.3293,  -63.7064,\n",
       "            57.9286,  -61.5101],\n",
       "         [  65.6633,   68.0643,   39.3329,   25.2051,   27.1197,   43.9070,\n",
       "            15.0057,   36.7543],\n",
       "         [ 108.7926,  -95.7948,   61.6342,  -68.4346,   69.0033, -115.9581,\n",
       "            54.7151, -126.8226],\n",
       "         [  54.5703,   83.0386,   50.8758,   42.5310,   11.0007,   43.8209,\n",
       "           -11.7647,   39.2229],\n",
       "         [ 113.0976,  -92.4054,   62.4024,  -62.9187,   68.5263, -123.4696,\n",
       "            59.2970, -119.0273],\n",
       "         [  89.4485,   69.6594,   48.2706,   50.2335,   -1.1152,   55.0128,\n",
       "            -9.2364,   34.5233],\n",
       "         [  91.4719,  -65.7766,   74.6372,  -63.7205,   78.5699, -110.0561,\n",
       "            83.7141,  -88.9958],\n",
       "         [  73.4507,   25.6249,   33.8185,   35.8909,   -9.9588,   43.6399,\n",
       "           -16.8970,   38.6636]],\n",
       "\n",
       "        [[   4.7719, -115.0200,   47.4283,  -78.2764,   95.2440,  -82.9219,\n",
       "            99.2201,  -65.0072],\n",
       "         [ 152.5073,  -25.4179,  139.4446,  -21.6531,   82.6811,   -6.1288,\n",
       "            71.8893,   -9.9348],\n",
       "         [  11.8270, -112.6171,   31.1872,  -89.4743,   76.2787,  -86.8127,\n",
       "           136.4451,  -67.0515],\n",
       "         [ 209.1011,  -57.6982,  167.2789,  -18.4122,  129.2471,   -5.5163,\n",
       "           122.3844,   46.6505],\n",
       "         [  26.5014, -142.4658,   28.7669,  -92.2680,   76.3102,  -97.2321,\n",
       "           108.4666,  -74.2584],\n",
       "         [ 184.7188, -104.7921,  169.2692,  -44.4103,  121.3112,   -2.3724,\n",
       "           110.5622,   34.1593],\n",
       "         [ -46.1702, -131.9211,  -10.1191,  -91.1546,   34.5933,  -82.8985,\n",
       "            74.0469,  -53.3895],\n",
       "         [ 173.5987,  -93.5207,  127.3543,  -37.7475,   59.6053,  -39.1904,\n",
       "            59.8164,   17.6368]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e11 = nn.Conv2d(14, 64, kernel_size=5, padding=1)\n",
    "xe11 = relu(e11(dataset['obsvariable'])) #64x6x6\n",
    "\n",
    "e12 = nn.Conv2d(64, 128, kernel_size=5, padding=1)\n",
    "xe12 = relu(e12(xe11)) #128x4x4\n",
    "\n",
    "upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "xu1 = upconv1(xe12) #64x8x8\n",
    "\n",
    "outconv = nn.Conv2d(64, 5, kernel_size=1)\n",
    "out = outconv(xu1)\n",
    "out.shape\n",
    "out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_class:int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.e11 = nn.Conv2d(14, 64, kernel_size=5, padding=1)\n",
    "        self.e12 = nn.Conv2d(64, 128, kernel_size=5, padding=1)\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.outconv = nn.Conv2d(64, n_class, kernel_size=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "\n",
    "        xe11 = self.e11(x)\n",
    "        xe12 = self.e12(xe11)\n",
    "        xu1 = self.upconv1(xe12)\n",
    "        out = self.outconv(xu1)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class UNet(nn.Module):\n",
    "#     def __init__(self, n_class:int):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.e11 = nn.Conv2d(in_channels=14, out_channels=64, kernel_size=4, padding=1)\n",
    "#         self.e12 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, padding=1) \n",
    "#         self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "#         self.e21 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, padding=1)\n",
    "#         self.e22 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=4, padding=1) \n",
    "#         self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "#         self.e31 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, padding=1)\n",
    "#         self.e32 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=4, padding=1) \n",
    "#         self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "#         self.e41 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, padding=1)\n",
    "#         self.e42 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=4, padding=1) \n",
    "#         self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "#         self.e51 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=4, padding=1) \n",
    "#         self.e52 = nn.Conv2d(in_channels=1024, out_channels=n_class, kernel_size=12, padding=1) \n",
    "\n",
    "#     def forward(self, x: torch.Tensor):\n",
    "\n",
    "#         xe11 = relu(self.e11(x))\n",
    "#         xe12 = relu(self.e12(xe11))\n",
    "#         xp1 = self.pool1(xe12)\n",
    "\n",
    "#         xe21 = relu(self.e21(xp1))\n",
    "#         xe22 = relu(self.e22(xe21))\n",
    "#         xp2 = self.pool2(xe22)\n",
    "\n",
    "#         xe31 = relu(self.e31(xp2))\n",
    "#         xe32 = relu(self.e32(xe31))\n",
    "#         xp3 = self.pool3(xe32)\n",
    "\n",
    "#         xe41 = relu(self.e41(xp3))\n",
    "#         xe42 = relu(self.e42(xe41))\n",
    "#         xp4 = self.pool4(xe42)\n",
    "\n",
    "#         xe51 = relu(self.e51(xp4))\n",
    "#         xe52 = relu(self.e52(xe51))\n",
    "\n",
    "#         return xe52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(n_class=len(labels['AFG']))\n",
    "output = model(train_dataset[1]['obsvariable'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Segmentation(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    A LightningModule designed to perform image segmentation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 train_dataloader: DataLoader,\n",
    "                 val_dataloader: DataLoader,\n",
    "                 model: nn.Module,\n",
    "                 criterion: callable,\n",
    "                 learning_rate: float,\n",
    "                 metric: callable,\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Construct a Segmentation LightningModule.\n",
    "        Note that we keep hyperparameters separate from dataloaders to prevent data leakage at test time.\n",
    "        :param train_dataloader: Dataloader with training data, left as None at test time\n",
    "        :param val_dataloader: Dataloader with validation data, left as None at test time\n",
    "        :param model: PyTorch model\n",
    "        :param criterion: PyTorch loss function against which to train model\n",
    "        :param learning_rate: Float learning rate for our optimiser\n",
    "        :param metric: PyTorch function for model evaluation\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.val_dataloader = val_dataloader\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.learning_rate = learning_rate\n",
    "        self.metric = metric\n",
    "\n",
    "    def training_step(self, batch: dict, batch_idx: int):\n",
    "        \"\"\"\n",
    "        Perform a pass through a batch of training data.\n",
    "        :param batch: Batch of image pairs\n",
    "        :param batch_idx: Index of batch\n",
    "        :return: Loss from this batch of data for use in backprop\n",
    "        \"\"\"\n",
    "        x, y  = batch[\"obsvariable\"], batch[\"groundtruth\"]\n",
    "        y_hat = self.model(x)\n",
    "        # loss = torch.sqrt(self.criterion(y_hat, y)+1e-6)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y  = batch[\"obsvariable\"], batch[\"groundtruth\"]\n",
    "        y_hat = self.model(x)\n",
    "        # loss = torch.sqrt(self.criterion(y_hat, y)+1e-6)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        metric = self.metric(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_metric\", metric)\n",
    "        return loss\n",
    "\n",
    "    def testing_step(self, batch, batch_idx):\n",
    "        x, y  = batch[\"sar\"], batch[\"chart\"]\n",
    "        y_hat = self.model(x)\n",
    "        # loss = torch.sqrt(self.criterion(y_hat, y)+1e-6)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        metric = self.metric(y_hat, y)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_metric\", metric)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return {\n",
    "            \"optimizer\": optimizer\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = OpenSendaiBenchDataset( obsvariables_path=\"/obsvariables/\", \n",
    "                                        groundtruth_path=\"/groundtruth/\", \n",
    "                                        country='AFG', \n",
    "                                        signals = ['VH','VV','aerosol','blue','green','red','red1','red2','red3','nir','red4','vapor','swir1','swir2'])\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True)\n",
    "val_dataset = OpenSendaiBenchDataset(   obsvariables_path=\"/obsvariables/\", \n",
    "                                        groundtruth_path=\"/groundtruth/\", \n",
    "                                        country='AFG', \n",
    "                                        signals = ['VH','VV','aerosol','blue','green','red','red1','red2','red3','nir','red4','vapor','swir1','swir2'])\n",
    "val_dataloader = DataLoader(val_dataset, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "model = UNet(n_class=len(labels['AFG']))\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 1e-4\n",
    "metric = nn.MSELoss()\n",
    "segmenter = Segmentation(train_dataloader, val_dataloader, \n",
    "                         model, criterion, learning_rate, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:yzssolch) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cosmic-dew-28</strong> at: <a href='https://wandb.ai/opensendaibench/opensendaibench/runs/yzssolch' target=\"_blank\">https://wandb.ai/opensendaibench/opensendaibench/runs/yzssolch</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240116_230503-yzssolch/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:yzssolch). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/joshuadimasaka/Desktop/PhD/GitHub/OpenSendaiBench/wandb/run-20240116_230815-0znciggw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/opensendaibench/opensendaibench/runs/0znciggw' target=\"_blank\">clear-sky-29</a></strong> to <a href='https://wandb.ai/opensendaibench/opensendaibench' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/opensendaibench/opensendaibench' target=\"_blank\">https://wandb.ai/opensendaibench/opensendaibench</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/opensendaibench/opensendaibench/runs/0znciggw' target=\"_blank\">https://wandb.ai/opensendaibench/opensendaibench/runs/0znciggw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuadimasaka/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:389: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"opensendaibench\")  # initialise wandb\n",
    "wandb_logger = pl.loggers.WandbLogger(project=\"opensendaibench\")  # create a logger object\n",
    "wandb_logger.watch(model, log=\"all\", log_freq=10)  # tell our logger to watch the model we are training to track parameters and gradients\n",
    "wandb_logger.experiment.config.update(  # log experimental config items of interest\n",
    "    {\n",
    "        \"learning_rate\": learning_rate\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type    | Params\n",
      "--------------------------------------\n",
      "0 | model     | UNet    | 260 K \n",
      "1 | criterion | MSELoss | 0     \n",
      "2 | metric    | MSELoss | 0     \n",
      "--------------------------------------\n",
      "260 K     Trainable params\n",
      "0         Non-trainable params\n",
      "260 K     Total params\n",
      "1.042     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuadimasaka/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:492: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/Users/joshuadimasaka/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/Users/joshuadimasaka/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 100/100 [00:07<00:00, 13.92it/s, v_num=iggw]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 100/100 [00:07<00:00, 13.89it/s, v_num=iggw]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "trainer = pl.Trainer(max_epochs=25) \n",
    "trainer.logger = wandb_logger  \n",
    "trainer.callbacks.append(ModelCheckpoint(monitor=\"val_loss\")) \n",
    "trainer.fit(segmenter, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
      "        [ 3.,  2.,  3.,  3.,  4.,  3.,  0.,  0.],\n",
      "        [ 2.,  2.,  2.,  3.,  3.,  4.,  0.,  1.],\n",
      "        [ 7.,  6., 10., 10.,  2.,  1.,  0.,  0.],\n",
      "        [ 7.,  7., 10., 10.,  1.,  1.,  0.,  0.]])\n",
      "[[ 0  0  1  3  3  1  3  2]\n",
      " [ 3  2  5  4  4  5  3  2]\n",
      " [ 1  5  4  1  3  6  2  4]\n",
      " [ 3  1  4  0  5  5 -1  0]\n",
      " [ 1  2  1  1  3  2  0 -2]\n",
      " [ 1 -1 -2  1  4  4  2  0]\n",
      " [ 3  4  0  2  3  5  0  0]\n",
      " [ 2  1  5  1  3  3  0  3]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 2\n",
    "j = 5\n",
    "output = model(val_dataset[j]['obsvariable'])\n",
    "output = output.detach().numpy()\n",
    "map = output[i,:,:]\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(val_dataset[j][\"groundtruth\"][i,:,:])\n",
    "plt.title(\"True Chart\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "img = plt.imshow(map)\n",
    "plt.colorbar(img)\n",
    "plt.title(\"Predicted Chart\")\n",
    "\n",
    "print(val_dataset[j][\"groundtruth\"][i,:,:])\n",
    "print(map.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opensendaibench",
   "language": "python",
   "name": "opensendaibench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
