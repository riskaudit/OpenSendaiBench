{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import rioxarray as rxr\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image \n",
    "from constants import labels\n",
    "\n",
    "from constants import labels\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import copy\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torch.nn.functional import relu\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenSendaiBenchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    An implementation of a PyTorch dataset for loading pairs of observable variables and ground truth labels.\n",
    "    Inspired by https://pytorch.org/tutorials/beginner/data_loading_tutorial.html.\n",
    "    \"\"\"\n",
    "    def __init__(self, obsvariables_path: str, groundtruth_path: str, country: str, signals: list, transform: transforms = None):\n",
    "        \"\"\"\n",
    "        Constructs an OpenSendaiBenchDataset.\n",
    "        :param obsvariables_path: Path to the source folder of observable variables\n",
    "        :param groundtruth_path: Path to the source folder of corresponding ground truth labels\n",
    "        :param transform: Callable transformation to apply to images upon loading\n",
    "        \"\"\"\n",
    "        self.obsvariables_path = obsvariables_path\n",
    "        self.groundtruth_path = groundtruth_path\n",
    "        self.country = country\n",
    "        self.signals = signals\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Implements the len(SeaIceDataset) magic method. Required to implement by Dataset superclass.\n",
    "        When training/testing, this method tells our training loop how much longer we have to go in our Dataset.\n",
    "        :return: Length of OpenSendaiBenchDataset\n",
    "        \"\"\"\n",
    "        return 100 #len(self.groundtruth_files)/labels[self.country]\n",
    "\n",
    "    def __getitem__(self, i: int):\n",
    "        \"\"\"\n",
    "        Implements the OpenSendaiBenchDataset[i] magic method. Required to implement by Dataset superclass.\n",
    "        When training/testing, this method is used to actually fetch data.\n",
    "        :param i: Index of which image pair to fetch\n",
    "        :return: Dictionary with pairs of observable variables and ground truth labels.\n",
    "        \"\"\"\n",
    "\n",
    "        obsvariable = np.zeros([len(self.signals),372,372])\n",
    "        obsvariable_8x8 = np.zeros([len(self.signals),8,8])\n",
    "        for s in range(len(self.signals)):\n",
    "            for file in glob.glob(str(os.getcwd()+self.obsvariables_path+\n",
    "                                    '**/'+self.country+'_*/'+self.country+'_'+\n",
    "                                    str(i)+'_'+'of_*/2019*_'+self.signals[s]+'.tif')):\n",
    "                a = cv2.imread(file, cv2.IMREAD_UNCHANGED)\n",
    "                a = a.reshape(1,a.shape[0],a.shape[1])\n",
    "                obsvariable[s,:,:] = a[0,0:372,0:372]\n",
    "            obsvariable_8x8[s,:,:] = cv2.resize(obsvariable[s,:,:], (8,8), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "        groundtruth = np.zeros([len(labels[self.country]),8,8])\n",
    "        for w in range(len(labels[self.country])): # to make composite. in AFG, we got 5 bldgtypes\n",
    "            for file in glob.glob(str(os.getcwd()+self.groundtruth_path+\n",
    "                                      self.country+'*/tiles/images/'+\n",
    "                                      self.country+'_nbldg_'+labels[self.country][w]+'_'+str(i)+'_'+'of_'+'*.tif')):\n",
    "                a = cv2.imread(file, cv2.IMREAD_UNCHANGED)\n",
    "                # a = cv2.resize(a, (372,372), interpolation = cv2.INTER_NEAREST)\n",
    "                a = a.reshape(1,a.shape[0],a.shape[1])\n",
    "                groundtruth[w,:,:] = a\n",
    "\n",
    "        obsvariable = torch.from_numpy(obsvariable).float()\n",
    "        obsvariable_8x8 = torch.from_numpy(obsvariable_8x8).float()\n",
    "        groundtruth = torch.from_numpy(groundtruth).float()\n",
    "    \n",
    "        sample = {\"obsvariable\": obsvariable_8x8, \"groundtruth\": groundtruth}\n",
    "        if self.transform:\n",
    "            sample = {\"obsvariable\": self.transform(obsvariable_8x8),\n",
    "                      \"groundtruth\": self.transform(groundtruth).squeeze(0).long()}\n",
    "        return sample\n",
    "\n",
    "    def visualise(self, i):\n",
    "        \"\"\"\n",
    "        Allows us to visualise a particular SAR/chart pair.\n",
    "        :param i: Index of which image pair to visualise\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        sample = self[i]\n",
    "        fig1, axs1 = plt.subplots(1,len(self.signals))\n",
    "        for s in range(len(self.signals)):\n",
    "            axs1[s].imshow(sample['obsvariable'][s,:,:])\n",
    "            axs1[s].set_title(str(self.signals[s]))\n",
    "            axs1[s].set_xticks([])\n",
    "            axs1[s].set_yticks([])\n",
    "        plt.tight_layout()\n",
    " \n",
    "        fig2, axs2 = plt.subplots(1,len(labels[self.country]))\n",
    "        for w in range(len(labels[self.country])): \n",
    "            axs2[w].imshow(sample['groundtruth'][w,:,:])\n",
    "            axs2[w].set_title(labels[self.country][w])\n",
    "            axs2[w].set_xticks([])\n",
    "            axs2[w].set_yticks([])\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = OpenSendaiBenchDataset( obsvariables_path=\"/obsvariables/\", \n",
    "                                        groundtruth_path=\"/groundtruth/\", \n",
    "                                        country='AFG', \n",
    "                                        signals = ['VH','VV','aerosol','blue','green','red','red1','red2','red3','nir','red4','vapor','swir1','swir2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class UNet(nn.Module):\n",
    "#     def __init__(self, n_class:int):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.e11 = nn.Conv2d(in_channels=14, out_channels=64, kernel_size=4, padding=1)\n",
    "#         self.e12 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, padding=1) \n",
    "#         self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "#         self.e21 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, padding=1)\n",
    "#         self.e22 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=4, padding=1) \n",
    "#         self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "#         self.e31 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, padding=1)\n",
    "#         self.e32 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=4, padding=1) \n",
    "#         self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "#         self.e41 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, padding=1)\n",
    "#         self.e42 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=4, padding=1) \n",
    "#         self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "#         self.e51 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=4, padding=1) \n",
    "#         self.e52 = nn.Conv2d(in_channels=1024, out_channels=n_class, kernel_size=12, padding=1) \n",
    "\n",
    "#     def forward(self, x: torch.Tensor):\n",
    "\n",
    "#         xe11 = relu(self.e11(x))\n",
    "#         xe12 = relu(self.e12(xe11))\n",
    "#         xp1 = self.pool1(xe12)\n",
    "\n",
    "#         xe21 = relu(self.e21(xp1))\n",
    "#         xe22 = relu(self.e22(xe21))\n",
    "#         xp2 = self.pool2(xe22)\n",
    "\n",
    "#         xe31 = relu(self.e31(xp2))\n",
    "#         xe32 = relu(self.e32(xe31))\n",
    "#         xp3 = self.pool3(xe32)\n",
    "\n",
    "#         xe41 = relu(self.e41(xp3))\n",
    "#         xe42 = relu(self.e42(xe41))\n",
    "#         xp4 = self.pool4(xe42)\n",
    "\n",
    "#         xe51 = relu(self.e51(xp4))\n",
    "#         xe52 = relu(self.e52(xe51))\n",
    "\n",
    "#         return xe52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(n_class=len(labels['AFG']))\n",
    "output = model(train_dataset[1]['obsvariable'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Segmentation(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    A LightningModule designed to perform image segmentation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 train_dataloader: DataLoader,\n",
    "                 val_dataloader: DataLoader,\n",
    "                 model: nn.Module,\n",
    "                 criterion: callable,\n",
    "                 learning_rate: float,\n",
    "                 metric: callable,\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Construct a Segmentation LightningModule.\n",
    "        Note that we keep hyperparameters separate from dataloaders to prevent data leakage at test time.\n",
    "        :param train_dataloader: Dataloader with training data, left as None at test time\n",
    "        :param val_dataloader: Dataloader with validation data, left as None at test time\n",
    "        :param model: PyTorch model\n",
    "        :param criterion: PyTorch loss function against which to train model\n",
    "        :param learning_rate: Float learning rate for our optimiser\n",
    "        :param metric: PyTorch function for model evaluation\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.val_dataloader = val_dataloader\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.learning_rate = learning_rate\n",
    "        self.metric = metric\n",
    "\n",
    "    def training_step(self, batch: dict, batch_idx: int):\n",
    "        \"\"\"\n",
    "        Perform a pass through a batch of training data.\n",
    "        :param batch: Batch of image pairs\n",
    "        :param batch_idx: Index of batch\n",
    "        :return: Loss from this batch of data for use in backprop\n",
    "        \"\"\"\n",
    "        x, y  = batch[\"obsvariable\"], batch[\"groundtruth\"]\n",
    "        y_hat = self.model(x)\n",
    "        # loss = torch.sqrt(self.criterion(y_hat, y)+1e-6)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y  = batch[\"obsvariable\"], batch[\"groundtruth\"]\n",
    "        y_hat = self.model(x)\n",
    "        # loss = torch.sqrt(self.criterion(y_hat, y)+1e-6)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        metric = self.metric(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_metric\", metric)\n",
    "        return loss\n",
    "\n",
    "    def testing_step(self, batch, batch_idx):\n",
    "        x, y  = batch[\"sar\"], batch[\"chart\"]\n",
    "        y_hat = self.model(x)\n",
    "        # loss = torch.sqrt(self.criterion(y_hat, y)+1e-6)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        metric = self.metric(y_hat, y)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_metric\", metric)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return {\n",
    "            \"optimizer\": optimizer\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = OpenSendaiBenchDataset( obsvariables_path=\"/obsvariables/\", \n",
    "                                        groundtruth_path=\"/groundtruth/\", \n",
    "                                        country='AFG', \n",
    "                                        signals = ['VH','VV','aerosol','blue','green','red','red1','red2','red3','nir','red4','vapor','swir1','swir2'])\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True)\n",
    "val_dataset = OpenSendaiBenchDataset(   obsvariables_path=\"/obsvariables/\", \n",
    "                                        groundtruth_path=\"/groundtruth/\", \n",
    "                                        country='AFG', \n",
    "                                        signals = ['VH','VV','aerosol','blue','green','red','red1','red2','red3','nir','red4','vapor','swir1','swir2'])\n",
    "val_dataloader = DataLoader(val_dataset, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "model = UNet(n_class=len(labels['AFG']))\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 1e-4\n",
    "metric = nn.MSELoss()\n",
    "segmenter = Segmentation(train_dataloader, val_dataloader, \n",
    "                         model, criterion, learning_rate, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:d7nf6icc) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">divine-cherry-19</strong> at: <a href='https://wandb.ai/opensendaibench/opensendaibench/runs/d7nf6icc' target=\"_blank\">https://wandb.ai/opensendaibench/opensendaibench/runs/d7nf6icc</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240116_205404-d7nf6icc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:d7nf6icc). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/joshuadimasaka/Desktop/PhD/GitHub/OpenSendaiBench/wandb/run-20240116_205522-ji8gus7z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/opensendaibench/opensendaibench/runs/ji8gus7z' target=\"_blank\">pleasant-deluge-20</a></strong> to <a href='https://wandb.ai/opensendaibench/opensendaibench' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/opensendaibench/opensendaibench' target=\"_blank\">https://wandb.ai/opensendaibench/opensendaibench</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/opensendaibench/opensendaibench/runs/ji8gus7z' target=\"_blank\">https://wandb.ai/opensendaibench/opensendaibench/runs/ji8gus7z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuadimasaka/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:389: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"opensendaibench\")  # initialise wandb\n",
    "wandb_logger = pl.loggers.WandbLogger(project=\"opensendaibench\")  # create a logger object\n",
    "wandb_logger.watch(model, log=\"all\", log_freq=10)  # tell our logger to watch the model we are training to track parameters and gradients\n",
    "wandb_logger.experiment.config.update(  # log experimental config items of interest\n",
    "    {\n",
    "        \"learning_rate\": learning_rate\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type    | Params\n",
      "--------------------------------------\n",
      "0 | model     | UNet    | 26.3 M\n",
      "1 | criterion | MSELoss | 0     \n",
      "2 | metric    | MSELoss | 0     \n",
      "--------------------------------------\n",
      "26.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "26.3 M    Total params\n",
      "105.139   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuadimasaka/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:492: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/Users/joshuadimasaka/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (4 x 4). Kernel size: (5 x 5). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m trainer\u001b[38;5;241m.\u001b[39mlogger \u001b[38;5;241m=\u001b[39m wandb_logger  \n\u001b[1;32m      4\u001b[0m trainer\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mappend(ModelCheckpoint(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \n\u001b[0;32m----> 5\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(segmenter, train_dataloader, val_dataloader)\n",
      "File \u001b[0;32m~/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_and_handle_interrupt(\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    546\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(model, ckpt_path\u001b[38;5;241m=\u001b[39mckpt_path)\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:989\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 989\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_stage()\n\u001b[1;32m    991\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    994\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1033\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1033\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1062\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1059\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1062\u001b[0m val_loop\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m   1064\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/pytorch_lightning/loops/utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loop_run(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py:134\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py:391\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    385\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    386\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    390\u001b[0m )\n\u001b[0;32m--> 391\u001b[0m output \u001b[38;5;241m=\u001b[39m call\u001b[38;5;241m.\u001b[39m_call_strategy_hook(trainer, hook_name, \u001b[38;5;241m*\u001b[39mstep_args)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 309\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    312\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py:403\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mvalidation_step(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[22], line 48\u001b[0m, in \u001b[0;36mSegmentation.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[1;32m     47\u001b[0m     x, y  \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobsvariable\u001b[39m\u001b[38;5;124m\"\u001b[39m], batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroundtruth\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 48\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# loss = torch.sqrt(self.criterion(y_hat, y)+1e-6)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(y_hat, y)\n",
      "File \u001b[0;32m~/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1566\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1570\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1571\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1572\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1573\u001b[0m     ):\n\u001b[1;32m   1574\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[21], line 30\u001b[0m, in \u001b[0;36mUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m xe12 \u001b[38;5;241m=\u001b[39m relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39me12(xe11))\n\u001b[1;32m     28\u001b[0m xp1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1(xe12)\n\u001b[0;32m---> 30\u001b[0m xe21 \u001b[38;5;241m=\u001b[39m relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39me21(xp1))\n\u001b[1;32m     31\u001b[0m xe22 \u001b[38;5;241m=\u001b[39m relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39me22(xe21))\n\u001b[1;32m     32\u001b[0m xp2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool2(xe22)\n",
      "File \u001b[0;32m~/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1566\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1570\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1571\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1572\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1573\u001b[0m     ):\n\u001b[1;32m   1574\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/miniconda3/envs/opensendaibench/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (4 x 4). Kernel size: (5 x 5). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "trainer = pl.Trainer(max_epochs=10) \n",
    "trainer.logger = wandb_logger  \n",
    "trainer.callbacks.append(ModelCheckpoint(monitor=\"val_loss\")) \n",
    "trainer.fit(segmenter, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Predicted Chart')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 3\n",
    "j = 0\n",
    "output = model(val_dataset[j]['obsvariable'])\n",
    "output = output.detach().numpy()\n",
    "map = output[i,:,:]\n",
    "print(map)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(val_dataset[j][\"groundtruth\"][i,:,:])\n",
    "plt.title(\"True Chart\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "img = plt.imshow(map)\n",
    "plt.colorbar(img)\n",
    "plt.title(\"Predicted Chart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opensendaibench",
   "language": "python",
   "name": "opensendaibench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
