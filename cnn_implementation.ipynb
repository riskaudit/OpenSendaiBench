{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import rioxarray as rxr\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image \n",
    "from constants import labels\n",
    "\n",
    "from constants import labels\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import copy\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torch.nn.functional import relu\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenSendaiBenchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    An implementation of a PyTorch dataset for loading pairs of observable variables and ground truth labels.\n",
    "    Inspired by https://pytorch.org/tutorials/beginner/data_loading_tutorial.html.\n",
    "    \"\"\"\n",
    "    def __init__(self, obsvariables_path: str, groundtruth_path: str, country: str, signals: list, transform: transforms = None):\n",
    "        \"\"\"\n",
    "        Constructs an OpenSendaiBenchDataset.\n",
    "        :param obsvariables_path: Path to the source folder of observable variables\n",
    "        :param groundtruth_path: Path to the source folder of corresponding ground truth labels\n",
    "        :param transform: Callable transformation to apply to images upon loading\n",
    "        \"\"\"\n",
    "        self.obsvariables_path = obsvariables_path\n",
    "        self.groundtruth_path = groundtruth_path\n",
    "        self.country = country\n",
    "        self.signals = signals\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Implements the len(SeaIceDataset) magic method. Required to implement by Dataset superclass.\n",
    "        When training/testing, this method tells our training loop how much longer we have to go in our Dataset.\n",
    "        :return: Length of OpenSendaiBenchDataset\n",
    "        \"\"\"\n",
    "        return 100 #len(self.groundtruth_files)/labels[self.country]\n",
    "\n",
    "    def __getitem__(self, i: int):\n",
    "        \"\"\"\n",
    "        Implements the OpenSendaiBenchDataset[i] magic method. Required to implement by Dataset superclass.\n",
    "        When training/testing, this method is used to actually fetch data.\n",
    "        :param i: Index of which image pair to fetch\n",
    "        :return: Dictionary with pairs of observable variables and ground truth labels.\n",
    "        \"\"\"\n",
    "\n",
    "        obsvariable = np.zeros([len(self.signals),372,372])\n",
    "        for s in range(len(self.signals)):\n",
    "            for file in glob.glob(str(os.getcwd()+self.obsvariables_path+\n",
    "                                    '**/'+self.country+'_*/'+self.country+'_'+\n",
    "                                    str(i)+'_'+'of_*/2019*_'+self.signals[s]+'.tif')):\n",
    "                a = cv2.imread(file, cv2.IMREAD_UNCHANGED)\n",
    "                a = a.reshape(1,a.shape[0],a.shape[1])\n",
    "                obsvariable[s,:,:] = a[0,0:372,0:372]\n",
    "                \n",
    "        groundtruth = np.zeros([len(labels[self.country]),8,8])\n",
    "        for w in range(len(labels[self.country])): # to make composite. in AFG, we got 5 bldgtypes\n",
    "            for file in glob.glob(str(os.getcwd()+self.groundtruth_path+\n",
    "                                      self.country+'*/tiles/images/'+\n",
    "                                      self.country+'_nbldg_'+labels[self.country][w]+'_'+str(i)+'_'+'of_'+'*.tif')):\n",
    "                a = cv2.imread(file, cv2.IMREAD_UNCHANGED)\n",
    "                # a = cv2.resize(a, (372,372), interpolation = cv2.INTER_NEAREST)\n",
    "                a = a.reshape(1,a.shape[0],a.shape[1])\n",
    "                groundtruth[w,:,:] = a\n",
    "\n",
    "        obsvariable = torch.from_numpy(obsvariable).float()\n",
    "        groundtruth = torch.from_numpy(groundtruth).float()\n",
    "    \n",
    "        sample = {\"obsvariable\": obsvariable, \"groundtruth\": groundtruth}\n",
    "        if self.transform:\n",
    "            sample = {\"obsvariable\": self.transform(obsvariable),\n",
    "                      \"groundtruth\": self.transform(groundtruth).squeeze(0).long()}\n",
    "        return sample\n",
    "\n",
    "    def visualise(self, i):\n",
    "        \"\"\"\n",
    "        Allows us to visualise a particular SAR/chart pair.\n",
    "        :param i: Index of which image pair to visualise\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        sample = self[i]\n",
    "        fig1, axs1 = plt.subplots(1,len(self.signals))\n",
    "        for s in range(len(self.signals)):\n",
    "            axs1[s].imshow(sample['obsvariable'][s,:,:])\n",
    "            axs1[s].set_title(str(self.signals[s]))\n",
    "            axs1[s].set_xticks([])\n",
    "            axs1[s].set_yticks([])\n",
    "        plt.tight_layout()\n",
    " \n",
    "        fig2, axs2 = plt.subplots(1,len(labels[self.country]))\n",
    "        for w in range(len(labels[self.country])): \n",
    "            axs2[w].imshow(sample['groundtruth'][w,:,:])\n",
    "            axs2[w].set_title(labels[self.country][w])\n",
    "            axs2[w].set_xticks([])\n",
    "            axs2[w].set_yticks([])\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_class:int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.e11 = nn.Conv2d(in_channels=14, out_channels=64, kernel_size=5, padding=1)\n",
    "        self.e12 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=5, padding=1) \n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.e21 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, padding=1)\n",
    "        self.e22 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=5, padding=1) \n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.e31 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5, padding=1)\n",
    "        self.e32 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=5, padding=1) \n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.e41 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=5, padding=1)\n",
    "        self.e42 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=5, padding=1) \n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.e51 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=5, padding=1) \n",
    "        self.e52 = nn.Conv2d(in_channels=1024, out_channels=n_class, kernel_size=12, padding=1) \n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "\n",
    "        xe11 = relu(self.e11(x))\n",
    "        xe12 = relu(self.e12(xe11))\n",
    "        xp1 = self.pool1(xe12)\n",
    "\n",
    "        xe21 = relu(self.e21(xp1))\n",
    "        xe22 = relu(self.e22(xe21))\n",
    "        xp2 = self.pool2(xe22)\n",
    "\n",
    "        xe31 = relu(self.e31(xp2))\n",
    "        xe32 = relu(self.e32(xe31))\n",
    "        xp3 = self.pool3(xe32)\n",
    "\n",
    "        xe41 = relu(self.e41(xp3))\n",
    "        xe42 = relu(self.e42(xe41))\n",
    "        xp4 = self.pool4(xe42)\n",
    "\n",
    "        xe51 = relu(self.e51(xp4))\n",
    "        xe52 = relu(self.e52(xe51))\n",
    "\n",
    "        return xe52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Segmentation(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    A LightningModule designed to perform image segmentation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 train_dataloader: DataLoader,\n",
    "                 val_dataloader: DataLoader,\n",
    "                 model: nn.Module,\n",
    "                 criterion: callable,\n",
    "                 learning_rate: float,\n",
    "                 metric: callable,\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Construct a Segmentation LightningModule.\n",
    "        Note that we keep hyperparameters separate from dataloaders to prevent data leakage at test time.\n",
    "        :param train_dataloader: Dataloader with training data, left as None at test time\n",
    "        :param val_dataloader: Dataloader with validation data, left as None at test time\n",
    "        :param model: PyTorch model\n",
    "        :param criterion: PyTorch loss function against which to train model\n",
    "        :param learning_rate: Float learning rate for our optimiser\n",
    "        :param metric: PyTorch function for model evaluation\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.val_dataloader = val_dataloader\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.learning_rate = learning_rate\n",
    "        self.metric = metric\n",
    "\n",
    "    def training_step(self, batch: dict, batch_idx: int):\n",
    "        \"\"\"\n",
    "        Perform a pass through a batch of training data.\n",
    "        :param batch: Batch of image pairs\n",
    "        :param batch_idx: Index of batch\n",
    "        :return: Loss from this batch of data for use in backprop\n",
    "        \"\"\"\n",
    "        x, y  = batch[\"obsvariable\"], batch[\"groundtruth\"]\n",
    "        y_hat = self.model(x)\n",
    "        # loss = torch.sqrt(self.criterion(y_hat, y)+1e-6)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y  = batch[\"obsvariable\"], batch[\"groundtruth\"]\n",
    "        y_hat = self.model(x)\n",
    "        # loss = torch.sqrt(self.criterion(y_hat, y)+1e-6)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        metric = self.metric(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_metric\", metric)\n",
    "        return loss\n",
    "\n",
    "    def testing_step(self, batch, batch_idx):\n",
    "        x, y  = batch[\"sar\"], batch[\"chart\"]\n",
    "        y_hat = self.model(x)\n",
    "        # loss = torch.sqrt(self.criterion(y_hat, y)+1e-6)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        metric = self.metric(y_hat, y)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_metric\", metric)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return {\n",
    "            \"optimizer\": optimizer\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = OpenSendaiBenchDataset( obsvariables_path=\"/obsvariables/\", \n",
    "                                        groundtruth_path=\"/groundtruth/\", \n",
    "                                        country='AFG', \n",
    "                                        signals = ['VH','VV','aerosol','blue','green','red','red1','red2','red3','nir','red4','vapor','swir1','swir2'])\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True)\n",
    "val_dataset = OpenSendaiBenchDataset(   obsvariables_path=\"/obsvariables/\", \n",
    "                                        groundtruth_path=\"/groundtruth/\", \n",
    "                                        country='AFG', \n",
    "                                        signals = ['VH','VV','aerosol','blue','green','red','red1','red2','red3','nir','red4','vapor','swir1','swir2'])\n",
    "val_dataloader = DataLoader(val_dataset, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "model = UNet(n_class=len(labels['AFG']))\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 1e-4\n",
    "metric = nn.MSELoss()\n",
    "segmenter = Segmentation(train_dataloader, val_dataloader, \n",
    "                         model, criterion, learning_rate, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"opensendaibench\")  # initialise wandb\n",
    "wandb_logger = pl.loggers.WandbLogger(project=\"opensendaibench\")  # create a logger object\n",
    "wandb_logger.watch(model, log=\"all\", log_freq=10)  # tell our logger to watch the model we are training to track parameters and gradients\n",
    "wandb_logger.experiment.config.update(  # log experimental config items of interest\n",
    "    {\n",
    "        \"learning_rate\": learning_rate\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "trainer = pl.Trainer(max_epochs=500) \n",
    "trainer.logger = wandb_logger  \n",
    "trainer.callbacks.append(ModelCheckpoint(monitor=\"val_loss\")) \n",
    "trainer.fit(segmenter, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(val_dataloader))\n",
    "output = model(batch[\"obsvariable\"])\n",
    "output.shape\n",
    "map = output[0,4,:,:]\n",
    "plt.imshow(batch[\"groundtruth\"][0,4,:,:])\n",
    "plt.title(\"True Chart\")\n",
    "plt.show()\n",
    "img = plt.imshow(map.detach().numpy()) # convert torch tensor to numpy array before passing into matplotlib\n",
    "plt.colorbar(img)\n",
    "plt.title(\"Predicted Chart\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opensendaibench",
   "language": "python",
   "name": "opensendaibench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
